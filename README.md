# MLsecurity_fall22

## Before Midproject

### 11-26 - 11-27
1. Starting from the [colab](https://colab.research.google.com/drive/1W0lE-rA8NNJlFUxvRndx6TeXK7CVKkDg)
2. Adopted a model (?) and the dataset (fair(?) and unfair(?)) and run the code for attention visualization
3. Find suitable datasets/pretrained models. 

[Visualization Toolkit Github](https://github.com/jessevig/bertviz)

[Datasets1](https://www.kaggle.com/datasets/crowdflower/twitter-user-gender-classification)
[Datasets2](https://github.com/pliang279/LM_bias)


### 11-28
1. Retrain on the fair dataset and record our preliminary results.
2. Compare to the reference paper here.

### 11-29

### 11-30

### 12-1


### 12-2
submit the mid project

